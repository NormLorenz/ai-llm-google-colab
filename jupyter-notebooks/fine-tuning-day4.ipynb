{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "db8736a7-ed94-441c-9556-831fa57b5a10",
      "metadata": {
        "id": "db8736a7-ed94-441c-9556-831fa57b5a10"
      },
      "source": [
        "# The Product Pricer Continued\n",
        "\n",
        "A model that can estimate how much something costs, from its description.\n",
        "\n",
        "## Enter The Frontier!\n",
        "\n",
        "And now - we put Frontier Models to the test.\n",
        "\n",
        "### 2 important points:\n",
        "\n",
        "It's important to appreciate that we aren't Training the frontier models. We're only providing them with the Test dataset to see how they perform. They don't gain the benefit of the 400,000 training examples that we provided to the Traditional ML models.\n",
        "\n",
        "HAVING SAID THAT...\n",
        "\n",
        "It's entirely possible that in their monstrously large training data, they've already been exposed to all the products in the training AND the test set. So there could be test \"contamination\" here which gives them an unfair advantage. We should keep that in mind."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets==3.6.0 gensim anthropic"
      ],
      "metadata": {
        "id": "hj4mkBKMlEWQ"
      },
      "execution_count": null,
      "outputs": [],
      "id": "hj4mkBKMlEWQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "681c717b-4c24-4ac3-a5f3-3c5881d6e70a",
      "metadata": {
        "id": "681c717b-4c24-4ac3-a5f3-3c5881d6e70a"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "from dotenv import load_dotenv\n",
        "from huggingface_hub import login\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "from collections import Counter\n",
        "from openai import OpenAI\n",
        "from anthropic import Anthropic\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iW1y_Osz0Xiw"
      },
      "id": "iW1y_Osz0Xiw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keys\n",
        "\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "claude_api_key = userdata.get(\"ANTHROPIC_API_KEY\")\n",
        "hugging_face_token = userdata.get(\"HF_TOKEN\")"
      ],
      "metadata": {
        "id": "p9Q6RYX95nsA"
      },
      "execution_count": null,
      "outputs": [],
      "id": "p9Q6RYX95nsA"
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "os.environ['ANTHROPIC_API_KEY'] = claude_api_key\n",
        "os.environ['HF_TOKEN'] = hugging_face_token"
      ],
      "metadata": {
        "id": "wXG_8OvCwa5S"
      },
      "id": "wXG_8OvCwa5S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log in to HuggingFace\n",
        "\n",
        "login(hugging_face_token, add_to_git_credential=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p3YHC9JwV1A",
        "outputId": "26edfaa7-ed17-4bbd-ebe7-33686ebc5f2e"
      },
      "id": "3p3YHC9JwV1A",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the python files from github\n",
        "\n",
        "%%bash\n",
        "wget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/items.py\n",
        "wget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/loaders.py\n",
        "wget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/testing.py\n",
        "wget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/human_input.py\n",
        "wget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/human_output.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MefIb11pw0AX",
        "outputId": "6c8de733-7ef0-4f79-8ad7-cce14b0e1af8"
      },
      "id": "MefIb11pw0AX",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--2025-10-28 17:37:39--  https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/items.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3760 (3.7K) [text/plain]\n",
            "Saving to: ‘items.py’\n",
            "\n",
            "     0K ...                                                   100% 26.2M=0s\n",
            "\n",
            "2025-10-28 17:37:39 (26.2 MB/s) - ‘items.py’ saved [3760/3760]\n",
            "\n",
            "--2025-10-28 17:37:39--  https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/loaders.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2855 (2.8K) [text/plain]\n",
            "Saving to: ‘loaders.py’\n",
            "\n",
            "     0K ..                                                    100% 28.4M=0s\n",
            "\n",
            "2025-10-28 17:37:39 (28.4 MB/s) - ‘loaders.py’ saved [2855/2855]\n",
            "\n",
            "--2025-10-28 17:37:39--  https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/human_input.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-10-28 17:37:39 ERROR 404: Not Found.\n",
            "\n",
            "--2025-10-28 17:37:39--  https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/human_output.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-10-28 17:37:39 ERROR 404: Not Found.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'b'wget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/items.py\\nwget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/loaders.py\\n# wget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/testing.py\\nwget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/human_input.py\\nwget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/human_output.py\\n'' returned non-zero exit status 8.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1608256167.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/items.py\\nwget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/loaders.py\\n# wget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/testing.py\\nwget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/human_input.py\\nwget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/human_output.py\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'wget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/items.py\\nwget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/loaders.py\\n# wget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/testing.py\\nwget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/human_input.py\\nwget https://raw.githubusercontent.com/NormLorenz/ai-llm-google-colab/main/jupyter-notebooks/human_output.py\\n'' returned non-zero exit status 8."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6985bdc7-fa45-49a3-ae97-84bdeb9b2083",
      "metadata": {
        "id": "6985bdc7-fa45-49a3-ae97-84bdeb9b2083"
      },
      "outputs": [],
      "source": [
        "# And some more imports - with thanks to Alex C for pointing out that I need to do these after the HF login..\n",
        "# moved our Tester into a separate package\n",
        "# call it with Tester.test(function_name, test_dataset)\n",
        "\n",
        "from items import Item\n",
        "from loaders import ItemLoader\n",
        "from testing import Tester"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0a6fb86-74a4-403c-ab25-6db2d74e9d2b",
      "metadata": {
        "id": "b0a6fb86-74a4-403c-ab25-6db2d74e9d2b"
      },
      "outputs": [],
      "source": [
        "openai = OpenAI()\n",
        "claude = Anthropic()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c830ed3e-24ee-4af6-a07b-a1bfdcd39278",
      "metadata": {
        "id": "c830ed3e-24ee-4af6-a07b-a1bfdcd39278"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c9b05f4-c9eb-462c-8d86-de9140a2d985",
      "metadata": {
        "id": "5c9b05f4-c9eb-462c-8d86-de9140a2d985"
      },
      "outputs": [],
      "source": [
        "# Mount your Google Drive at the beginning of the session\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the file path in your Google Drive\n",
        "drive_path_one= '/content/drive/MyDrive/Colab Notebooks/train_lite.pkl'\n",
        "drive_path_two= '/content/drive/MyDrive/Colab Notebooks/test_lite.pkl'\n",
        "\n",
        "# Load the file\n",
        "with open(drive_path_one, 'rb') as file:\n",
        "    train = pickle.load(file)\n",
        "\n",
        "# Load the file\n",
        "with open(drive_path_two, 'rb') as file:\n",
        "    test = pickle.load(file)\n",
        "\n",
        "print(\"File loaded successfully:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5856173-e68c-4975-a769-5f1736e227a5",
      "metadata": {
        "id": "e5856173-e68c-4975-a769-5f1736e227a5"
      },
      "source": [
        "# Before we look at the Frontier\n",
        "\n",
        "## There is one more model we could consider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e81ee0-828a-4af8-9ccf-177af6c78a0c",
      "metadata": {
        "id": "f3e81ee0-828a-4af8-9ccf-177af6c78a0c"
      },
      "outputs": [],
      "source": [
        "# Write the test set to a CSV\n",
        "\n",
        "import csv\n",
        "with open('human_input.csv', 'w', encoding=\"utf-8\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    for t in test[:250]:\n",
        "        writer.writerow([t.test_prompt(), 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeafac31-1a10-4029-b190-030378e2fe01",
      "metadata": {
        "id": "aeafac31-1a10-4029-b190-030378e2fe01"
      },
      "outputs": [],
      "source": [
        "# Read it back in\n",
        "\n",
        "human_predictions = []\n",
        "with open('human_output.csv', 'r', encoding=\"utf-8\") as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    for row in reader:\n",
        "        human_predictions.append(float(row[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9709da2-28f0-419e-af71-4ef6c02246ad",
      "metadata": {
        "id": "a9709da2-28f0-419e-af71-4ef6c02246ad"
      },
      "outputs": [],
      "source": [
        "def human_pricer(item):\n",
        "    idx = test.index(item)\n",
        "    return human_predictions[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1ba3b3e-4b08-4f0b-9e51-ebb03a86085d",
      "metadata": {
        "id": "e1ba3b3e-4b08-4f0b-9e51-ebb03a86085d"
      },
      "outputs": [],
      "source": [
        "Tester.test(human_pricer, test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "066fef03-8338-4526-9df3-89b649ad4f0a",
      "metadata": {
        "id": "066fef03-8338-4526-9df3-89b649ad4f0a"
      },
      "source": [
        "## First, the humble but mighty GPT-4o-mini\n",
        "\n",
        "It's called mini, but it packs a punch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66ea68e8-ab1b-4f0d-aba4-a59574d8f85e",
      "metadata": {
        "id": "66ea68e8-ab1b-4f0d-aba4-a59574d8f85e"
      },
      "outputs": [],
      "source": [
        "# First let's work on a good prompt for a Frontier model\n",
        "# Notice that I'm removing the \" to the nearest dollar\"\n",
        "# When we train our own models, we'll need to make the problem as easy as possible,\n",
        "# but a Frontier model needs no such simplification.\n",
        "\n",
        "def messages_for(item):\n",
        "    system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
        "    user_prompt = item.test_prompt().replace(\" to the nearest dollar\",\"\").replace(\"\\n\\nPrice is $\",\"\")\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "        {\"role\": \"assistant\", \"content\": \"Price is $\"}\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "add7bc0a-71fb-49cc-a49b-9548fd0fe949",
      "metadata": {
        "id": "add7bc0a-71fb-49cc-a49b-9548fd0fe949"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ff92d61-0d27-4b0d-8b32-c9891016509b",
      "metadata": {
        "id": "4ff92d61-0d27-4b0d-8b32-c9891016509b"
      },
      "outputs": [],
      "source": [
        "# Try this out\n",
        "\n",
        "messages_for(test[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1af1888-f94a-4106-b0d8-8a70939eec4e",
      "metadata": {
        "id": "b1af1888-f94a-4106-b0d8-8a70939eec4e"
      },
      "outputs": [],
      "source": [
        "# A utility function to extract the price from a string\n",
        "\n",
        "def get_price(s):\n",
        "    s = s.replace('$','').replace(',','')\n",
        "    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", s)\n",
        "    return float(match.group()) if match else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f138c5b7-bcc1-4085-aced-68dad1bf36b4",
      "metadata": {
        "id": "f138c5b7-bcc1-4085-aced-68dad1bf36b4"
      },
      "outputs": [],
      "source": [
        "get_price(\"The price is roughly $99.99 because blah blah\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "501a2a7a-69c8-451b-bbc0-398bcb9e1612",
      "metadata": {
        "id": "501a2a7a-69c8-451b-bbc0-398bcb9e1612"
      },
      "outputs": [],
      "source": [
        "# The function for gpt-4o-mini\n",
        "\n",
        "def gpt_4o_mini(item):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages_for(item),\n",
        "        seed=42,\n",
        "        max_tokens=5\n",
        "    )\n",
        "    reply = response.choices[0].message.content\n",
        "    return get_price(reply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "843d88b4-364a-431b-b48b-8a7c1f68b786",
      "metadata": {
        "id": "843d88b4-364a-431b-b48b-8a7c1f68b786"
      },
      "outputs": [],
      "source": [
        "test[0].price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36bdd2c9-1859-4f99-a09f-3ec83b845b30",
      "metadata": {
        "id": "36bdd2c9-1859-4f99-a09f-3ec83b845b30"
      },
      "outputs": [],
      "source": [
        "Tester.test(gpt_4o_mini, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f49e90d6-6749-4eb8-9347-5922b189d379",
      "metadata": {
        "id": "f49e90d6-6749-4eb8-9347-5922b189d379"
      },
      "outputs": [],
      "source": [
        "def gpt_4o_frontier(item):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4o-2024-08-06\",\n",
        "        messages=messages_for(item),\n",
        "        seed=42,\n",
        "        max_tokens=5\n",
        "    )\n",
        "    reply = response.choices[0].message.content\n",
        "    return get_price(reply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "766e697e-55bf-4521-b301-3b07d20045e0",
      "metadata": {
        "id": "766e697e-55bf-4521-b301-3b07d20045e0"
      },
      "outputs": [],
      "source": [
        "# The function for gpt-4o - the August model\n",
        "# Note that it cost me about 1-2 cents to run this (pricing may vary by region)\n",
        "# You can skip this and look at my results instead\n",
        "\n",
        "Tester.test(gpt_4o_frontier, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53d941cb-5b73-44ea-b893-3a0ce9997066",
      "metadata": {
        "id": "53d941cb-5b73-44ea-b893-3a0ce9997066"
      },
      "outputs": [],
      "source": [
        "def claude_3_point_5_sonnet(item):\n",
        "    messages = messages_for(item)\n",
        "    system_message = messages[0]['content']\n",
        "    messages = messages[1:]\n",
        "    response = claude.messages.create(\n",
        "        model=\"claude-3-5-sonnet-20240620\",\n",
        "        max_tokens=5,\n",
        "        system=system_message,\n",
        "        messages=messages\n",
        "    )\n",
        "    reply = response.content[0].text\n",
        "    return get_price(reply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11dba25d-f562-40f9-9855-40b715b7fc86",
      "metadata": {
        "id": "11dba25d-f562-40f9-9855-40b715b7fc86"
      },
      "outputs": [],
      "source": [
        "# The function for Claude 3.5 Sonnet\n",
        "# It also cost me about 1-2 cents to run this (pricing may vary by region)\n",
        "# You can skip this and look at my results instead\n",
        "\n",
        "Tester.test(claude_3_point_5_sonnet, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77428dfb-d8f4-4477-8265-77b4b0badd39",
      "metadata": {
        "id": "77428dfb-d8f4-4477-8265-77b4b0badd39"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}